# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_xofvTw3xsLR5kskKjibsdYouXA__VpN
"""

import tensorflow as tf
from collections import Counter
import numpy as np
import matplotlib.pyplot as plt
import requests

# ======================
# 2. Load Dataset
# ======================
url = "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
response = requests.get(url)
text = response.text

print("Total characters:", len(text))
print("Sample text:\n", text[:500])

# ======================
# 3. Tokenization (word-level) with LIMITED VOCAB
# ======================
words = text.split()
print("Total words:", len(words))

# Build vocabulary with limit
VOCAB_LIMIT = 8000
word_counts = Counter(words)
vocab = [word for word, count in word_counts.most_common(VOCAB_LIMIT)]
vocab = vocab + ['<UNK>']
word_to_id = {word: idx for idx, word in enumerate(vocab)}
id_to_word = {idx: word for word, idx in word_to_id.items()}

print("Vocab size:", len(vocab))
print("Sample mapping:", list(word_to_id.items())[:10])

# Encode text with UNK handling
def encode_word(word):
    return word_to_id.get(word, word_to_id['<UNK>'])

encoded = [encode_word(word) for word in words]

# ======================
# 4. Create Input-Output Pairs
# ======================
seq_length = 30
inputs, outputs = [], []

for i in range(len(encoded) - seq_length):
    inputs.append(encoded[i:i+seq_length])
    outputs.append(encoded[i+seq_length])

inputs = np.array(inputs)
outputs = np.array(outputs)

print("Input shape:", inputs.shape)
print("Output shape:", outputs.shape)
print("Example input (ids):", inputs[0])
print("Example output (id):", outputs[0], "->", id_to_word[outputs[0]])

# ======================
# 5. Train/Val/Test Split
# ======================
total_size = len(inputs)
train_end = int(total_size * 0.8)
val_end = int(total_size * 0.9)

x_train, y_train = inputs[:train_end], outputs[:train_end]
x_val, y_val = inputs[train_end:val_end], outputs[train_end:val_end]
x_test, y_test = inputs[val_end:], outputs[val_end:]

print("Train size:", x_train.shape, y_train.shape)
print("Validation size:", x_val.shape, y_val.shape)
print("Test size:", x_test.shape, y_test.shape)

# ======================
# 6. Create TensorFlow Datasets
# ======================
BATCH_SIZE = 128
BUFFER_SIZE = 10000

train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_ds = val_ds.batch(BATCH_SIZE, drop_remainder=True)

test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_ds = test_ds.batch(BATCH_SIZE, drop_remainder=True)


# ======================
# 7. Build BETTER LSTM Model (Increased Capacity)
# ======================
VOCAB_SIZE = len(vocab)
EMBEDDING_DIM = 300  # Increased from 256
HIDDEN_UNITS = 600

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(
        input_dim=VOCAB_SIZE,
        output_dim=EMBEDDING_DIM,
        input_length=seq_length,
        name="embedding"
    ),

    tf.keras.layers.Bidirectional(
        tf.keras.layers.LSTM(HIDDEN_UNITS, return_sequences=True, dropout=0.3),
        name="bidirectional_lstm_1"
    ),
    tf.keras.layers.LSTM(HIDDEN_UNITS//2, dropout=0.25, name="lstm_3"),

    tf.keras.layers.Dense(600, activation='relu', name="dense_1"),
    tf.keras.layers.Dropout(0.4, name="dropout_4"),

    tf.keras.layers.Dense(VOCAB_SIZE, activation='softmax', name="output")
])

# ======================
# 8. Improved Training Configuration
# ======================
optimizer = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    clipvalue=1.0  # Gradient clipping to prevent explosions
)

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer=optimizer,
    metrics=['accuracy']
)

# ======================
# 9. Better Callbacks
# ======================
early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',  # Monitor loss instead of accuracy
    patience=10,         # Increased patience
    restore_best_weights=True,
    mode='min',
    verbose=1
)

lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.7,          # Less aggressive reduction
    patience=5,          # More patience before reducing
    min_lr=1e-6,
    verbose=1
)

# ======================
# 10. Train Model
# ======================
EPOCHS = 50

print("Starting training...")
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=[early_stop, lr_scheduler],
    verbose=1
)

# ======================
# 11. Evaluate on Test Set
# ======================
print("Evaluating on test set...")
test_loss, test_acc = model.evaluate(test_ds, verbose=1)
perplexity = np.exp(test_loss)

print(f"\n=== FINAL RESULTS ===")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_acc:.4f}")
print(f"Test Perplexity: {perplexity:.4f}")

# ======================
# 12. Plot Training Curves
# ======================
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.legend()

plt.tight_layout()
plt.show()

# ======================
# 13. Improved Text Generation
# ======================
def generate_text(model, seed_text, next_words=15, temperature=0.8):
    result = seed_text.split()

    for _ in range(next_words):
        # Convert last seq_length words to ids, handle UNK
        input_seq = [word_to_id.get(w, word_to_id['<UNK>']) for w in result[-seq_length:]]

        # Pad if necessary
        if len(input_seq) < seq_length:
            input_seq = [word_to_id['the']] * (seq_length - len(input_seq)) + input_seq  # Use 'the' instead of UNK

        input_seq = tf.expand_dims(input_seq, axis=0)

        # Predict probabilities
        preds = model.predict(input_seq, verbose=0)[0]

        # Remove UNK token from predictions (set probability to 0)
        unk_id = word_to_id['<UNK>']
        preds[unk_id] = 0
        preds = preds / np.sum(preds)  # Renormalize

        # Apply temperature sampling
        preds = np.log(preds + 1e-8) / temperature
        exp_preds = np.exp(preds)
        preds = exp_preds / np.sum(exp_preds)

        # Sample from top 5 predictions to avoid weird words
        top_5_indices = np.argsort(preds)[-5:]
        top_5_probs = preds[top_5_indices]
        top_5_probs = top_5_probs / np.sum(top_5_probs)  # Renormalize

        next_id = np.random.choice(top_5_indices, p=top_5_probs)
        next_word = id_to_word[next_id]

        result.append(next_word)

    return " ".join(result)

# Test generation
seed = "To be or not to"
print("\n=== GENERATED TEXT ===")
print("Temperature 0.8 (More coherent):")
print(generate_text(model, seed, temperature=0.8))
print("\nTemperature 1.0 (Balanced):")
print(generate_text(model, seed, temperature=1.0))